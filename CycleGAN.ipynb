{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "import os\nprint(os.listdir(\"../input\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "# Reference\nGitHub\n1. https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/cyclegan/cyclegan.py\n2. https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n\nPaper --\n[CycleGan]( https://arxiv.org/pdf/1703.10593.pdf)\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c52eb68ba413c78b69140d7ee3950fd8d22b966"
      },
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nfrom PIL import Image\nimport glob\nimport random\nimport itertools\nimport time\nimport datetime\n\n\n%matplotlib inline\n\nseed=2018\ntorch.manual_seed(seed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7d4e81b35060db5735b828d0300b1dd6f6206ab4"
      },
      "cell_type": "code",
      "source": "from os import walk\nfor (dirpath, dirnames, filenames) in walk(\"../input/monet2photo/\"):\n    print(\"Directory path: \", dirpath)\n    #print(\"Folder name: \", dirnames)\n    #print(\"Files name: \", filenames)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce902ede9c7400b59a8aa2616e719cafcfb1b08c"
      },
      "cell_type": "code",
      "source": "import imageio\ndef show_img(file_path):\n    img = imageio.imread(file_path)\n    plt.imshow(img)\nshow_img('../input/monet2photo/monet2photo/monet2photo/trainA/00001.jpg')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f3ae71a65ac63ebad3cd664ee49de078c23f2fe"
      },
      "cell_type": "code",
      "source": "class ImageDataset(Dataset):\n    def __init__(self,root,transforms_=None ,unaligned=False ,mode='train'):\n        self.transforms = transforms.Compose(transforms_)\n        self.unaligned = unaligned\n        self.files_A = sorted(glob.glob(os.path.join(root,'%sA' % mode) + '/*.*'))\n        self.files_B = sorted(glob.glob(os.path.join(root,'%sB' % mode) + '/*.*'))\n    def __getitem__(self,index):\n        item_A = self.transforms(Image.open(self.files_A[index % len(self.files_A)]))\n        if self.unaligned:\n            item_B = self.transforms(Image.open(self.files_B[random.randint(0,len(self.files_B)-1)]))\n        else:\n            item_B = self.transforms(Image.open(self.files_B[index % len(self.files_B)]))\n        \n        return {'A':item_A,'B':item_B}\n    def __len__(self):\n        return max(len(self.files_A),len(self.files_B))\n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f61f228d4b515421fa0013333bb268b28e81a639"
      },
      "cell_type": "code",
      "source": "data_root='../input/monet2photo/monet2photo/monet2photo'\nworkers = 2\ntest_workers = 1\nngpu = 1\nbatch_size = 1\ntest_batch_size = 5\nimage_size = 256\nepoch = 0\nn_epochs = 200\nlr = 0.0002\nbeta1 = 0.5\nbeta2 = 0.999\ndecay_epoch = 100\nnc = 3\nsample_interval = 100\nn_residual_blocks = 9",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c74a4d6ce920f80607942ffe7153d336b51360ab"
      },
      "cell_type": "code",
      "source": "cuda = torch.cuda.is_available() and ngpu > 0\nprint(cuda)\ndevice = 'cuda:0' if cuda else 'cpu'\nprint(device)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a952e82c6352650b11cd103cdaa8ddb2ba4f337"
      },
      "cell_type": "code",
      "source": "transforms_ = [ transforms.Resize(int(image_size*1.12), Image.BICUBIC),\n                transforms.RandomCrop(image_size),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "477d5f92033b643ed97534d80791d659bb2c6791"
      },
      "cell_type": "code",
      "source": "dataloader = DataLoader(ImageDataset(data_root, transforms_=transforms_, unaligned=True),\n                        batch_size=batch_size, shuffle=True, num_workers=workers)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fcb8a18cf76f3da599282881e2118bfbc4980a6c"
      },
      "cell_type": "code",
      "source": "val_dataloader = DataLoader(ImageDataset(data_root, transforms_=transforms_, unaligned=True, mode='test'),\n                        batch_size=test_batch_size, shuffle=True, num_workers=ngpu)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bbc240aaea87bb31e04d23230793efbd43d48500"
      },
      "cell_type": "markdown",
      "source": "# A is monet and B is photo"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "164acd3e8cfb668f1549ca3db3fab4b477b62158"
      },
      "cell_type": "code",
      "source": "train_batch = next(iter(dataloader))\ntrainAB_batch = torch.cat((train_batch['A'],train_batch['B'],train_batch['A'],train_batch['B']),0)\nplt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(vutils.make_grid(trainAB_batch.to(device), padding=2, normalize=True).cpu(),(1,2,0)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cfc4796890899817fe1d2963b9f88c858fdd83bd"
      },
      "cell_type": "code",
      "source": "def weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm2d') != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "66031733cfee5db6e4e0c494389ae048472e015a"
      },
      "cell_type": "markdown",
      "source": "# ResNet"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd9c7b41a16abaff90f435145ba891a466a3830c"
      },
      "cell_type": "code",
      "source": "class ResidualBlock(nn.Module):\n    def __init__(self,in_features):\n        super().__init__()\n        \n        conv_block = [ \n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features)\n        ]\n        self.conv_block = nn.Sequential(*conv_block)\n    def forward(self,x):\n        return x + self.conv_block(x)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "56d407f278a8dc203d7dd302c29e52b878621053"
      },
      "cell_type": "markdown",
      "source": "# Generator from Perceptual Losses for Real-Time Style Transfer and Super-Resolution\nhttps://arxiv.org/pdf/1603.08155.pdf"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "659a05f6ea25e3a8bf1f651ee9e2c2f110bfd039"
      },
      "cell_type": "code",
      "source": "class GeneratorResNet(nn.Module):\n    def __init__(self,in_channels=3,out_channels=3,res_blocks=9):\n        super().__init__()\n        \n        model = [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(in_channels, 64, 7),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True)\n        ]\n        # Downsample\n        in_features = 64\n        out_features = in_features * 2\n        for _ in range(2):\n            model += [\n                nn.Conv2d(in_features,out_features,3,stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            in_features = out_features\n            out_features = in_features * 2\n        \n        for _ in range(res_blocks):\n            model+= [ResidualBlock(in_features)]\n            \n        # Upsampleing\n        out_features = in_features // 2\n        for _ in range(2):\n            model += [\n                nn.ConvTranspose2d(in_features,out_features,3,stride=2, padding=1 , output_padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            in_features = out_features\n            out_features = in_features // 2\n        \n        model += [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(64, out_channels, 7),\n            nn.Tanh()\n        ]\n        \n        self.model = nn.Sequential(*model)\n        \n    def forward(self,x):\n        return self.model(x)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d3741aa1e42970e8bd9a6ad441a9bafd9093ac4a"
      },
      "cell_type": "markdown",
      "source": "Input: (N,C,H,W)\n[H+2p-d(k-1)-1]/s+1\n[256+2-(3)-1]/2+1=128\n64\n\n\n(output_size - 1) * stride + ksize\n(128-1)*2+4\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f2de015cdd7c04ef1beb7d8935530f748013f41b"
      },
      "cell_type": "code",
      "source": "class Discriminator(nn.Module):\n    def __init__(self, in_channels=3):\n        super().__init__()\n        \n        def discriminator_block(in_filters, out_filters ,normalize = True):\n            layers = [\n                nn.Conv2d(in_filters, out_filters , 4,stride=2,padding=1)\n            ]\n            if normalize:\n                layers.append(nn.InstanceNorm2d(out_filters))\n            layers.append(nn.LeakyReLU(0.2,inplace=True))\n            return layers\n        \n        self.model = nn.Sequential(\n            *discriminator_block(in_channels, 64, normalize=False),\n            *discriminator_block(64, 128),\n            *discriminator_block(128, 256),\n            *discriminator_block(256, 512),\n            nn.ZeroPad2d((1,0,1,0)), # left,right,top,bottom\n            nn.Conv2d(512,1,4,padding=1)\n        )\n    def forward(self,img):\n        return self.model(img)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "266b831af20c558b32ac465b95517679e6e60c6f"
      },
      "cell_type": "code",
      "source": "G_AB = GeneratorResNet(res_blocks=n_residual_blocks)\nG_BA = GeneratorResNet(res_blocks=n_residual_blocks)\nD_A = Discriminator()\nD_B = Discriminator()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24a55c3505eb334f7bb632eaa3394ec75b160bf6"
      },
      "cell_type": "code",
      "source": "criterion_cycle = nn.L1Loss()\ncriterion_identity = nn.L1Loss()\ncriterion_GAN = nn.MSELoss() # lsgan",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f70fbe0fa781701f09448d7fdac23afdcd44f0bc"
      },
      "cell_type": "code",
      "source": "if cuda:\n    G_AB = G_AB.cuda()\n    G_BA = G_BA.cuda()\n    D_A = D_A.cuda()\n    D_B = D_B.cuda()\n    criterion_GAN.cuda()\n    criterion_cycle.cuda()\n    criterion_identity.cuda()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bfdf4e564256a9b37a4144bc31ee269c00a89e43"
      },
      "cell_type": "code",
      "source": "G_AB.apply(weights_init_normal)\nG_BA.apply(weights_init_normal)\nD_A.apply(weights_init_normal)\nD_B.apply(weights_init_normal)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "123db706c264bd839bcd77fb75d002e642eb4371"
      },
      "cell_type": "code",
      "source": "lambda_cyc = 10\nlambda_identity = 0.5 * lambda_cyc",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b4c1b2fa4b752ac81c2e7814bd21f3e0eed2986"
      },
      "cell_type": "code",
      "source": "def sample_images(batch_i):\n    imgs = next(iter(val_dataloader))\n    real_A = Variable(imgs['A'].to(device))\n    real_B = Variable(imgs['B'].to(device))\n    fake_A = G_BA(real_B)\n    fake_B = G_AB(real_A)\n    img_sample = torch.cat((real_A.data,fake_B.data,real_B.data,fake_A.data),0)\n    plt.figure(figsize=(12,12))\n    plt.axis(\"off\")\n    plt.title(\"Sample Images {}\".format(batch_i))\n    plt.imshow(np.transpose(vutils.make_grid(img_sample.to(device), padding=2, normalize=True).cpu(),(1,2,0)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e750d4345b9b73db64fe63a64dc32739a40fbe7d"
      },
      "cell_type": "code",
      "source": "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()),\n                                lr=lr, betas=(beta1, beta2))\noptimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, beta2))\noptimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, beta2))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7ad5288de74bc36bfdb9dff93009381d78f795d"
      },
      "cell_type": "code",
      "source": "class LambdaLR():\n    def __init__(self, n_epochs, offset, decay_start_epoch):\n        assert (n_epochs > decay_start_epoch), \"Decay must start before the training session ends!\"\n        self.n_epochs = n_epochs\n        self.offset = offset\n        self.decay_start_epoch = decay_start_epoch\n    def step(self, epoch):\n        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n        ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58b0c46450084a4b6abdb80d926a0ddaa356e326"
      },
      "cell_type": "code",
      "source": "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\nlr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\nlr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0f155d4b7f049ccaa345a7ff8e9e1b4517e2a0f"
      },
      "cell_type": "code",
      "source": "class ReplayBuffer():\n    def __init__(self,max_size=50):\n        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n        self.max_size = max_size\n        self.data = []\n    def push_and_pop(self,data):\n        to_return=[]\n        for element in data.data:\n            element = torch.unsqueeze(element, 0)\n            if len(self.data) < self.max_size:\n                self.data.append(element)\n                to_return.append(element)\n            else:\n                if random.uniform(0,1) > 0.5:\n                    i = random.randint(0, self.max_size-1)\n                    to_return.append(self.data[i].clone())\n                    self.data[i] = element\n                else:\n                    to_return.append(element)\n        return Variable(torch.cat(to_return))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5fdebb481a4963f5b834c1801983cf0eef353ab0"
      },
      "cell_type": "code",
      "source": "fake_A_buffer = ReplayBuffer()\nfake_B_buffer = ReplayBuffer()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cda59b404b9dda881837c6927439f3459c58ed01"
      },
      "cell_type": "markdown",
      "source": "# Training"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d3b6d6b656f6eb99c8dd6334d7577437e53b9077"
      },
      "cell_type": "code",
      "source": "patch = (1, image_size // 2**4, image_size // 2**4)\nprint(patch)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1fb4475cf3dc4d961da89c2b61531cc60b701be"
      },
      "cell_type": "code",
      "source": "prev_time=time.time()\nfor epoch in range(n_epochs):\n    for i, batch in enumerate(dataloader):\n        \n        # set model input\n        real_A = Variable(batch['A'].to(device))\n        real_B = Variable(batch['B'].to(device))\n        \n        valid = Variable(torch.ones((1, *patch)).to(device))\n        fake = Variable(torch.zeros((1, *patch)).to(device))\n        \n        # Train G\n        optimizer_G.zero_grad()\n        # identityloss\n        loss_id_A = criterion_identity(G_BA(real_A), real_A)\n        loss_id_B = criterion_identity(G_AB(real_B), real_B)\n        loss_identity = (loss_id_A + loss_id_B) / 2\n        \n        # GanLoss\n        fake_B = G_AB(real_A)\n        loss_GAN_AB=criterion_GAN(D_B(fake_B),valid)\n        fake_A = G_BA(real_B)\n        loss_GAN_BA=criterion_GAN(D_A(fake_A),valid)\n        loss_GAN = (loss_GAN_AB+loss_GAN_BA)/2\n        \n        # CycleGan\n        recov_A = G_BA(fake_B)\n        loss_cycle_A = criterion_cycle(recov_A,real_A)\n        recov_B = G_AB(fake_A)\n        loss_cycle_B = criterion_cycle(recov_B,real_B)\n        loss_cycle = (loss_cycle_A+loss_cycle_B)/2\n        \n        # Totloss\n        loss_G = loss_GAN + lambda_cyc*loss_cycle + lambda_identity*loss_identity\n        loss_G.backward()\n        optimizer_G.step()\n        \n        # Train D_A\n        optimizer_D_A.zero_grad()\n        loss_real = criterion_GAN(D_A(real_A),valid)\n        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n        loss_fake = criterion_GAN(D_A(fake_A_.detach()),fake)\n        loss_D_A = (loss_real+loss_fake)/2\n        loss_D_A.backward()\n        optimizer_D_A.step()\n        # Train D_B\n        optimizer_D_B.zero_grad()\n        loss_real = criterion_GAN(D_B(real_B),valid)\n        fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n        loss_fake = criterion_GAN(D_B(fake_B_.detach()),fake)\n        loss_D_B = (loss_real+loss_fake)/2\n        loss_D_B.backward()\n        optimizer_D_B.step()\n        \n        loss_D = (loss_D_A+loss_D_B)/2\n        \n        # Log_process\n        batch_done = epoch * len(dataloader) + i\n        batches_left = n_epochs * len(dataloader) - batch_done\n        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n        prev_time = time.time()\n        print('[Epoch {}/{}] [Batch {}/{}] [D loss: {}] [G loss: {}, adv: {}, cycle: {}, identity: {}] ETA: {}'.format(\n                                                        epoch, n_epochs,\n                                                        i, len(dataloader),\n                                                        loss_D.item(), loss_G.item(),\n                                                        loss_GAN.item(), loss_cycle.item(),\n                                                        loss_identity.item(), time_left))\n        if batch_done % sample_interval==0:\n            sample_images(batch_done)\n    lr_scheduler_G.step()\n    lr_scheduler_D_A.step()\n    lr_scheduler_D_B.step()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}